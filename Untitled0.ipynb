{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPkAwhTG0/Iq64gzqNc+BQH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nawel-Bellil/Energy-Efficiency-Monitoring-Security-in-ATM-SITRE/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXWJhghzHzBr",
        "outputId": "0fffffdb-a690-4b6f-ac9d-9fcb9539d1bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Facial-Recognition-using-Facenet' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/akshaybahadur21/Facial-Recognition-using-Facenet.git\n",
        "!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(\"/content\"):\n",
        "    for file in files:\n",
        "        if \"requirements.txt\" in file:\n",
        "            print(os.path.join(root, file))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4bfhUcOIrIV",
        "outputId": "a304eeb0-8cfb-4372-e4f0-c815337f86ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cleaned_requirements.txt\n",
            "/content/Facial-Recognition-using-Facenet/cleaned_requirements.txt\n",
            "/content/Facial-Recognition-using-Facenet/requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head /content/Facial-Recognition-using-Facenet/requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVF63DtWJItn",
        "outputId": "ce0da4b1-bff9-439d-e3af-75402d445df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy~=1.19.5\n",
            "matplotlib~=3.4.2\n",
            "dlib~=19.22.0\n",
            "scipy>=1.10.0\n",
            "keras~=2.4.3\n",
            "pillow\n",
            "opencv-python>=4.5.3\n",
            "h5py~=3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMJB_NRUKGjD",
        "outputId": "b5ff4928-2418-457d-832d-cc7155527a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/Facial-Recognition-using-Facenet/requirements.txt', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Remove 'pip:' and fix the indentation\n",
        "cleaned_lines = [line.strip() for line in lines if not line.startswith('pip:')]\n",
        "\n",
        "# Save the cleaned lines to a new file\n",
        "with open('/content/cleaned_requirements.txt', 'w') as f:\n",
        "    f.write(\"\\n\".join(cleaned_lines))\n",
        "\n",
        "# Install dependencies from the cleaned file\n",
        "!pip install -r /content/cleaned_requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq50wtdRILLt",
        "outputId": "01adf4b2-5a0b-40ff-b66b-ff08c53053ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy~=1.19.5 (from -r /content/cleaned_requirements.txt (line 1))\n",
            "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.4.2 in /usr/local/lib/python3.9/dist-packages (from -r /content/cleaned_requirements.txt (line 2)) (3.4.3)\n",
            "Requirement already satisfied: dlib~=19.22.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/cleaned_requirements.txt (line 3)) (19.22.1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/cleaned_requirements.txt (line 4)) (1.10.1)\n",
            "Collecting keras~=2.4.3 (from -r /content/cleaned_requirements.txt (line 5))\n",
            "  Downloading Keras-2.4.3-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from -r /content/cleaned_requirements.txt (line 6)) (11.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.3 in /usr/local/lib/python3.9/dist-packages (from -r /content/cleaned_requirements.txt (line 7)) (4.11.0.86)\n",
            "Collecting h5py~=3.1.0 (from -r /content/cleaned_requirements.txt (line 8))\n",
            "  Using cached h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.4.2->-r /content/cleaned_requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.4.2->-r /content/cleaned_requirements.txt (line 2)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib~=3.4.2->-r /content/cleaned_requirements.txt (line 2)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.4.2->-r /content/cleaned_requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from keras~=2.4.3->-r /content/cleaned_requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib~=3.4.2->-r /content/cleaned_requirements.txt (line 2)) (1.16.0)\n",
            "Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
            "Using cached h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
            "Installing collected packages: numpy, h5py, keras\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.13.0\n",
            "    Uninstalling h5py-3.13.0:\n",
            "      Successfully uninstalled h5py-3.13.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.9.2\n",
            "    Uninstalling keras-3.9.2:\n",
            "      Successfully uninstalled keras-3.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ml-dtypes 0.5.1 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires h5py>=3.11.0, but you have h5py 3.1.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires keras>=3.5.0, but you have keras 2.4.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.1.0 keras-2.4.3 numpy-1.19.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y libhdf5-dev\n",
        "!apt-get install -y build-essential\n",
        "!apt-get install -y python3-dev\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZPWml3YLUiK",
        "outputId": "5cb6bd5d-a45b-4839-c5d4-0ebc10d1ea3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libhdf5-dev is already the newest version (1.10.7+repack-4ubuntu2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.10.6-1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip cache purge\n",
        "!pip install --no-cache-dir h5py==3.6.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI5trzBUQGuQ",
        "outputId": "6680eec6-b233-4f9a-e170-b6f2648374d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files removed: 58 (65.4 MB)\n",
            "Collecting h5py==3.6.0\n",
            "  Downloading h5py-3.6.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from h5py==3.6.0) (1.19.5)\n",
            "Downloading h5py-3.6.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.19.0 requires h5py>=3.11.0, but you have h5py 3.6.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires keras>=3.5.0, but you have keras 2.4.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cython\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO5ZjY50QKKR",
        "outputId": "032f539a-d038-42ab-b19b-5487c9e9d81b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (3.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir h5py==3.6.0 --global-option=build_ext --global-option=\"-I/usr/include/hdf5/serial\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVq09GXHQNE_",
        "outputId": "d01c6626-d025-493e-f55b-c69c7f0756e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mDEPRECATION: --build-option and --global-option are deprecated. A possible replacement is to use --config-settings. Discussion can be found at https://github.com/pypa/pip/issues/11859\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Implying --no-binary=:all: due to the presence of --build-option / --global-option.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: h5py==3.6.0 in /usr/local/lib/python3.9/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from h5py==3.6.0) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py==3.7.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjReo1lKQPle",
        "outputId": "6ccde458-0e43-4a96-83fa-a1a33c19c588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==3.7.0\n",
            "  Downloading h5py-3.7.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from h5py==3.7.0) (1.19.5)\n",
            "Downloading h5py-3.7.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.6.0\n",
            "    Uninstalling h5py-3.6.0:\n",
            "      Successfully uninstalled h5py-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.19.0 requires h5py>=3.11.0, but you have h5py 3.7.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires keras>=3.5.0, but you have keras 2.4.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!df -h\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOP9hgl-QR04",
        "outputId": "bddadeb8-f337-4e82-ddc7-836eab0bad29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   40G   73G  36% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.7G     0  5.7G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  820M  59% /usr/sbin/docker-init\n",
            "tmpfs           6.4G   41M  6.3G   1% /var/colab\n",
            "/dev/sda1        92G   70G   23G  76% /kaggle/input\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py==3.4.0 --find-links https://www.lfd.uci.edu/~gohlke/pythonlibs/#h5py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDLLziBpPFL-",
        "outputId": "266c7664-b87d-4ed5-d80f-984f09a09202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://www.lfd.uci.edu/~gohlke/pythonlibs/#h5py\n",
            "Collecting h5py==3.4.0\n",
            "  Downloading h5py-3.4.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/dist-packages (from h5py==3.4.0) (1.19.5)\n",
            "Downloading h5py-3.4.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.7.0\n",
            "    Uninstalling h5py-3.7.0:\n",
            "      Successfully uninstalled h5py-3.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.19.0 requires h5py>=3.11.0, but you have h5py 3.4.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires keras>=3.5.0, but you have keras 2.4.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py==3.6.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMaNCqQFPNIP",
        "outputId": "95f58647-5407-4fd1-df80-ed3363f3c37c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==3.6.0\n",
            "  Downloading h5py-3.6.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from h5py==3.6.0) (1.19.5)\n",
            "Downloading h5py-3.6.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.4.0\n",
            "    Uninstalling h5py-3.4.0:\n",
            "      Successfully uninstalled h5py-3.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.19.0 requires h5py>=3.11.0, but you have h5py 3.6.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires keras>=3.5.0, but you have keras 2.4.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -c conda-forge h5py=3.4.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXdUwCpPPQKA",
        "outputId": "e6b2b248-d4f0-4d55-ea60-5de0278184cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py==3.4.0 --no-cache-dir\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7ajFGoJLXKp",
        "outputId": "188a1430-74ff-431e-ccff-492450848d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==3.4.0\n",
            "  Downloading h5py-3.4.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/dist-packages (from h5py==3.4.0) (1.19.5)\n",
            "Downloading h5py-3.4.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.6.0\n",
            "    Uninstalling h5py-3.6.0:\n",
            "      Successfully uninstalled h5py-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.19.0 requires h5py>=3.11.0, but you have h5py 3.4.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires keras>=3.5.0, but you have keras 2.4.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9 python3.9-dev python3.9-distutils -y\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python3.9 get-pip.py\n",
        "\n",
        "# Create a virtual environment with Python 3.9\n",
        "!python3.9 -m pip install virtualenv\n",
        "!python3.9 -m virtualenv py39_env\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O97PoA3sTEy5",
        "outputId": "a3f9cf8e-2e47-454d-fdc2-6089ba23111c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.9 is already the newest version (3.9.22-1+jammy1).\n",
            "python3.9-dev is already the newest version (3.9.22-1+jammy1).\n",
            "python3.9-distutils is already the newest version (3.9.22-1+jammy1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "--2025-04-11 20:05:28--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2300175 (2.2M) [text/x-python]\n",
            "Saving to: ‘get-pip.py.4’\n",
            "\n",
            "get-pip.py.4        100%[===================>]   2.19M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-04-11 20:05:28 (45.4 MB/s) - ‘get-pip.py.4’ saved [2300175/2300175]\n",
            "\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 25.0.1\n",
            "    Uninstalling pip-25.0.1:\n",
            "      Successfully uninstalled pip-25.0.1\n",
            "Successfully installed pip-25.0.1\n",
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.9/dist-packages (20.30.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.9/dist-packages (from virtualenv) (0.3.9)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.9/dist-packages (from virtualenv) (3.18.0)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.9/dist-packages (from virtualenv) (4.3.7)\n",
            "created virtual environment CPython3.9.22.final.0-64 in 267ms\n",
            "  creator CPython3Posix(dest=/content/py39_env, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: h5py==3.4.0, numpy==2.0.2, pip==25.0.1, setuptools==78.1.0, wheel==0.45.1\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Activate virtualenv\n",
        "!source py39_env/bin/activate && pip install h5py==3.4.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhuixEpvTHYy",
        "outputId": "fd069c23-ace1-43e4-dd2a-1fded6579d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py==3.4.0 in ./py39_env/lib/python3.9/site-packages (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in ./py39_env/lib/python3.9/site-packages (from h5py==3.4.0) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install h5py==3.8.0\n",
        "!pip install -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt\n",
        "!python train.py --img 640 --batch 16 --epochs 50 --data dataset.yaml --weights yolov5s.pt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHIoh7cWUADw",
        "outputId": "f9547e14-120f-458b-b7a4-f01774e56577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (25.0.1)\n",
            "Collecting h5py==3.8.0\n",
            "  Downloading h5py-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from h5py==3.8.0) (1.19.5)\n",
            "Downloading h5py-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.4.0\n",
            "    Uninstalling h5py-3.4.0:\n",
            "      Successfully uninstalled h5py-3.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.19.0 requires h5py>=3.11.0, but you have h5py 3.8.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires keras>=3.5.0, but you have keras 2.4.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.8.0\n",
            "Requirement already satisfied: numpy~=1.19.5 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: matplotlib~=3.4.2 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 2)) (3.4.3)\n",
            "Requirement already satisfied: dlib~=19.22.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 3)) (19.22.1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 4)) (1.10.1)\n",
            "Requirement already satisfied: keras~=2.4.3 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 5)) (2.4.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 6)) (11.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.3 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 7)) (4.11.0.86)\n",
            "Collecting h5py~=3.1.0 (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 8))\n",
            "  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.4.2->-r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.4.2->-r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 2)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib~=3.4.2->-r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 2)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.4.2->-r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from keras~=2.4.3->-r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib~=3.4.2->-r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 2)) (1.16.0)\n",
            "Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.8.0\n",
            "    Uninstalling h5py-3.8.0:\n",
            "      Successfully uninstalled h5py-3.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.19.0 requires h5py>=3.11.0, but you have h5py 3.1.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires keras>=3.5.0, but you have keras 2.4.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.1.0\n",
            "python3: can't open file '/content/train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/Facial-Recognition-using-Facenet/models/\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK_AxABkXiY-",
        "outputId": "2dfc3702-0f83-48be-dc3d-2106f8232226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "face-rec_Google.h5  shape_predictor_68_face_landmarks.dat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvv4GNJRZhd6",
        "outputId": "5f6c8dd0-bba9-48b6-dd33-b3eb3ff462d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy~=1.19.5 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: matplotlib~=3.4.2 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 2)) (3.4.3)\n",
            "Requirement already satisfied: dlib~=19.22.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 3)) (19.22.1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 4)) (1.10.1)\n",
            "Requirement already satisfied: keras~=2.4.3 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 5)) (2.4.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 6)) (11.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.3 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 7)) (4.11.0.86)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.9/dist-packages (from -r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.4.2->-r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.4.2->-r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 2)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib~=3.4.2->-r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 2)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib~=3.4.2->-r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from keras~=2.4.3->-r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib~=3.4.2->-r /content/Facial-Recognition-using-Facenet/cleaned_requirements.txt (line 2)) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VafDcP9JZj1J",
        "outputId": "c9dc5075-b85a-4a90-d494-c04b8cb27e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Facial-Recognition-using-Facenet/create_face.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1jfM16IZmZt",
        "outputId": "540362a4-4c1f-405c-9a2b-31c2378baf12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/Facial-Recognition-using-Facenet/create_face.py\", line 9, in <module>\n",
            "    shape_predictor = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Unable to open models/shape_predictor_68_face_landmarks.dat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Run the Face Recognition Application\n"
      ],
      "metadata": {
        "id": "W2wE_pm3Z4_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/Facial-Recognition-using-Facenet/models/face-rec_Google.h5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAUUO4sbcdYy",
        "outputId": "ac77cd55-7d14-4201-abbe-8810fb88684c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 15M Apr 11 18:33 /content/Facial-Recognition-using-Facenet/models/face-rec_Google.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/Facial-Recognition-using-Facenet/models/facenet_keras.h5 https://github.com/nyoki-mtl/keras-facenet/blob/master/model/facenet_keras.h5?raw=true\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JyxU9irfKBx",
        "outputId": "e2ad3e8f-04d1-4056-db2a-b7dc4e3707ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-11 20:13:50--  https://github.com/nyoki-mtl/keras-facenet/blob/master/model/facenet_keras.h5?raw=true\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-04-11 20:13:51 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "with h5py.File('/content/Facial-Recognition-using-Facenet/models/face-rec_Google.h5', 'r') as f:\n",
        "    print(list(f.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92b_pj8yf3KG",
        "outputId": "2f1eea4f-606d-460f-f543-f9dfe81ab522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['model_weights']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python /content/Facial-Recognition-using-Facenet/rec-feat.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FN2qDbLZ3JR",
        "outputId": "db55a14d-9179-4159-ac71-0af3c71050eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-11 20:18:51.109577: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744402731.130563   44860 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744402731.136762   44860 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-11 20:18:51.157688: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Facial-Recognition-using-Facenet/rec-feat.py\", line 12, in <module>\n",
            "    model.save_weights('/content/Facial-Recognition-using-Facenet/models/face-rec_Google.h5')\n",
            "    ^^^^^\n",
            "NameError: name 'model' is not defined. Did you mean: 'Model'?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Facial-Recognition-using-Facenet/Train-inception.py --img 640 --batch 16 --epochs 50 --data dataset.yaml --weights yolov5s.pt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pWO_NoAXlz9",
        "outputId": "8a5b32f1-34eb-4205-ecb4-27171739791c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-11 20:06:06.837205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744401966.873627   41374 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744401966.883939   41374 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-11 20:06:12.935568: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1744401972.942836   41374 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Facial-Recognition-using-Facenet/Train-inception.py\", line 39, in <module>\n",
            "    main()\n",
            "  File \"/content/Facial-Recognition-using-Facenet/Train-inception.py\", line 34, in main\n",
            "    FRmodel = faceRecoModel(input_shape=(96, 96, 3))  # Change here\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Facial-Recognition-using-Facenet/utils/inception_blocks_v2.py\", line 253, in faceRecoModel\n",
            "    X = inception_block_1a(X)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Facial-Recognition-using-Facenet/utils/inception_blocks_v2.py\", line 42, in inception_block_1a\n",
            "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/merging/concatenate.py\", line 178, in concatenate\n",
            "    return Concatenate(axis=axis, **kwargs)(inputs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/merging/concatenate.py\", line 99, in build\n",
            "    raise ValueError(err_msg)\n",
            "ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 128, 12, 192), (None, 32, 12, 192), (None, 32, 12, 102), (None, 64, 12, 192)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.9 -m venv venv_yolo && \\\n",
        "source venv_yolo/bin/activate && \\\n",
        "pip install --upgrade pip && \\\n",
        "pip install -r requirements.txt && \\\n",
        "python train.py --img 640 --batch 16 --epochs 50 --data dataset.yaml --weights yolov5s.pt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8EWHIq0H4Zm",
        "outputId": "db79c02f-6e3f-44d5-efd5-af857d0eb03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Command '['/content/venv_yolo/bin/python3.9', '-Im', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9bHEAXhT5UX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}